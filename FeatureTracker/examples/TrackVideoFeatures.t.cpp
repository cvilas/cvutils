//==============================================================================
// TrackVideoFeatures.t.cpp - Example program for FeatureTracker.. classes
// Vilas Chitrakaran, May 2006
// This test program uses the FFMPEG library to open a video file and tracks   
// user selected features from frame to frame.
//==============================================================================

//#define USE_KLT

#include "ffmpeg/avcodec.h"
#include "ffmpeg/avformat.h"
#ifdef USE_KLT
 #include "FeatureTrackerKLT.hpp"
#else
 #include "FeatureTrackerOCV.hpp"
#endif
#include <malloc.h>

#define TRACKED_FEATURES_TABLE_NAME      "./test0"

bool GetNextFrame(AVFormatContext *pFormatCtx, AVCodecContext *pCodecCtx, 
                  int videoStream, AVFrame *pFrame);

//============================================================================= 
// main - Demonstrates tracking features directly on a video file.
// This program uses a modified version of the example program available at 
// http://www.inb.uni-luebeck.de/~boehme/using_libavcodec.html
//============================================================================= 
int main(int argc, char *argv[])
{
 if(argc < 2) {
  fprintf(stderr, "Usage: %s <video_file>\n", argv[0]);
  return -1;
 }
 
 AVFormatContext *avFormatContext;
 FeatureTrackerContext_t tracContext;
#ifdef USE_KLT
 FeatureTrackerKLT tracker;
 KLT_TrackingContext tcxt;
 tcxt = KLTCreateTrackingContext();
 tcxt->lighting_insensitive = true;
 tcxt->writeInternalImages = false;
 tcxt->affineConsistencyCheck = -1;
 tcxt->window_width = 7;
 tcxt->window_height = 7;
 tcxt->max_iterations = 10;
 tcxt->mindist = 10;
 tcxt->smoothBeforeSelecting = true;

// tcxt->min_displacement = 0.1;
// tcxt->pyramid_sigma_fact = 0.9;
// tcxt->smooth_sigma_fact = 0.1;
// tcxt->grad_sigma = 1.5;
// KLTUpdateTCBorder(tcxt);
#else
 FeatureTrackerOCV tracker;
 OCVTrackingContext_t tcxt;
 tcxt.min_dist = 10;
 tcxt.quality = 0.01;
 tcxt.block_size = 9;
 tcxt.max_iter = 20;
 tcxt.epsilon = 0.01;
 tcxt.window_size = 10; 
 tcxt.max_error = 300;
#endif

 feature_list_t features;
 int frameNumber = 0;

 tracContext.num_features = 100;
 tracContext.num_frames = 200;
 tracContext.auto_select_features = true;
 tracContext.display_tracked_features = true;

 // create feature list
 if( allocateFeatureList(features, tracContext.num_features) < 0 )
  return -1;

 // initialize tracker
 if( tracker.initialize(tracContext, tcxt) != 0 ) {
  fprintf(stderr, "[%s] ERROR initializing tracker.\n", argv[0]);
  return -1;
 }

 // initialize libavcodec/libavformat, register codecs
 av_register_all();
 
 // open video file
 if( av_open_input_file(&avFormatContext, argv[1], NULL, 0, NULL) != 0 ) {
  fprintf(stderr, "[%s] ERROR av_open_input_file on %s failed\n", argv[0], argv[1]);
  return -1;
 }
 
 // get AV stream info
 if( av_find_stream_info(avFormatContext) < 0 ) {
  fprintf(stderr, "[%s] ERROR av_find_stream_info failed\n", argv[0]);
  return -1;
 }

 // print AV stream info to stderr
#ifndef NTO
 dump_format(avFormatContext, 0, argv[1], false);
#endif

 // find the first video stream
 int vStreamNum = -1;
 for(int i = 0; i < avFormatContext->nb_streams; i++) {
#ifdef NTO
  if( avFormatContext->streams[i]->codec.codec_type == CODEC_TYPE_VIDEO ) {
#else
  if( avFormatContext->streams[i]->codec->codec_type == CODEC_TYPE_VIDEO ) {
#endif
   vStreamNum = i;
   break;
  }
  if(vStreamNum == -1) {
   fprintf(stderr, "[%s] ERROR No video stream found in %s\n", argv[0], argv[1]);
   return -1;
  }
 }
 

 // find decoder
 AVCodecContext  *avCodecContext;
 AVCodec         *avCodec;
#ifdef NTO
 avCodecContext = &avFormatContext->streams[vStreamNum]->codec;
#else
 avCodecContext = avFormatContext->streams[vStreamNum]->codec;
#endif
 avCodec = avcodec_find_decoder(avCodecContext->codec_id);
 if(avCodec == NULL) {
   fprintf(stderr, "[%s] ERROR A suitable decoder not found\n", argv[0]);
   return -1;
 }

 // handle truncated bitstreams
 if( avCodec->capabilities & CODEC_CAP_TRUNCATED )
  avCodecContext->flags |= CODEC_FLAG_TRUNCATED;

 // open codec
 if(avcodec_open( avCodecContext, avCodec) < 0 ) {
   fprintf(stderr, "[%s] Error opening decoder\n", argv[0]);
   return -1;
 }

 // hack to correct wrong frame rates that seem to be generated by some 
 // codecs
 //if( avCodecContext->frame_rate > 1000 && avCodecContext->frame_rate_base == 1 )
 // avCodecContext->frame_rate_base = 1000;

 // allocate YUV video frame
 AVFrame *vFrame;
 if( (vFrame = avcodec_alloc_frame()) == NULL) {
   fprintf(stderr, "[%s] ERROR allocating frame structue\n", argv[0]);
   return -1;
 }

 // allocate GRAY8 frame
 AVFrame *vFrameGrey;
 if( (vFrameGrey = avcodec_alloc_frame()) == NULL) {
   fprintf(stderr, "[%s] ERROR allocating frame structue\n", argv[0]);
   return -1;
 }
 fprintf(stdout, "[%s] frame size: %d x %d\n", argv[0], avCodecContext->width, 
         avCodecContext->height);

 // allocate buffer
 int numBytes;
 uint8_t *buffer = NULL;
 numBytes = avpicture_get_size(PIX_FMT_GRAY8, avCodecContext->width,
            avCodecContext->height);
 buffer = (uint8_t *)malloc( numBytes * sizeof(uint8_t) );
 if( buffer == NULL ) {
   fprintf(stderr, "[%s] ERROR allocating memory for buffer\n", argv[0]);
   return -1;
 }

 // assign appropriate parts of buffer to image planes in avFrameGrey
 avpicture_fill( (AVPicture *)vFrameGrey, buffer, PIX_FMT_GRAY8,
                 avCodecContext->width, avCodecContext->height);

 int imgW = avCodecContext->width;
 int imgH = avCodecContext->height;
 
 fprintf(stdout, "[%s] Processing %d frames for %d features.\n", argv[0], 
         tracContext.num_frames, tracContext.num_features); 

 // Read frame from video one at a time, process them for feature points
 while( GetNextFrame(avFormatContext, avCodecContext, vStreamNum, vFrame) ) {

  // convert video frame from native format to grayscale
  img_convert( (AVPicture *)vFrameGrey, PIX_FMT_GRAY8, (AVPicture*)vFrame,
               avCodecContext->pix_fmt, imgW, imgH);

  // process image for features
  if( (frameNumber = tracker.processImage(vFrameGrey->data[0], imgW, imgH, features)) < 0 ) {
   if( frameNumber != -2) fprintf(stderr, "[%s] ERROR processing image.\n", argv[0]);
   return frameNumber;
  }
  fprintf(stdout, "\rProcessing frame:[%5d]", frameNumber);
  fflush(stdout);
  //if(frameNumber >= tracContext.num_frames)
  // break;
 }
 
#ifdef USE_KLT
 // Write the feature table, and an image with tracked features
 if( tracker.writeFeatureTable(TRACKED_FEATURES_TABLE_NAME) != 0 ) {
  fprintf(stderr, "[%s] ERROR writing feature tables.\n", argv[0]);
  return -1;
 }
 KLTFreeTrackingContext(tcxt);
#endif

 // cleanup
 free(buffer);
 av_free(vFrameGrey);
 av_free(vFrame);
 avcodec_close(avCodecContext);
 av_close_input_file(avFormatContext);
 freeFeatureList(features);
 return 0;
}


//============================================================================= 
// GetNextFrame
//============================================================================= 
bool GetNextFrame(AVFormatContext *pFormatCtx, AVCodecContext *pCodecCtx, 
    int videoStream, AVFrame *pFrame)
{
 static AVPacket packet;
 static int      bytesRemaining=0;
 static uint8_t  *rawData;
 static bool     fFirstTime=true;
 int             bytesDecoded;
 int             frameFinished;

 // First time we're called, set packet.data to NULL to indicate it
 // doesn't have to be freed
 if(fFirstTime) {
  fFirstTime = false;
  packet.data = NULL;
 }

 // Decode packets until we have decoded a complete frame
 while(true) {
  // Work on the current packet until we have decoded all of it
  while(bytesRemaining > 0) {
   // Decode the next chunk of data
   bytesDecoded = avcodec_decode_video(pCodecCtx, pFrame, &frameFinished, 
                  rawData, bytesRemaining);
   
   // Was there an error?
   if(bytesDecoded < 0) {
    fprintf(stderr, "Error while decoding frame\n");
    return false;
   }

   bytesRemaining -= bytesDecoded;
   rawData+=bytesDecoded;

   // Did we finish the current frame? Then we can return
   if(frameFinished)
    return true;
  }

  // Read the next packet, skipping all packets that aren't for this
  // stream
  do {
   // Free old packet
   if(packet.data != NULL)
   av_free_packet(&packet);

   // Read new packet
   if( av_read_packet(pFormatCtx, &packet) < 0 )
    goto loop_exit;
  } while(packet.stream_index != videoStream);

  bytesRemaining = packet.size;
  rawData = packet.data;
 }
 loop_exit:

 // Decode the rest of the last frame
 bytesDecoded = avcodec_decode_video(pCodecCtx, pFrame, &frameFinished,
                rawData, bytesRemaining);

 // Free last packet
 if(packet.data != NULL)
  av_free_packet(&packet);

 return frameFinished!=0;
}
